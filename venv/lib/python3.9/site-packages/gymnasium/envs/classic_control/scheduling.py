import sys
sys.path.append('/etc/kubernetes') 
from typing import Optional, Union
import numpy as np
import gymnasium as gym
from gymnasium import spaces
from model.main import node_count, get_worker_nodes_internal_ips, get_nodes_state
import time
import socket
import json
import matplotlib.pyplot as plt 
import dash
from dash import dcc, html, Input, Output
import multiprocessing
import plotly.graph_objs as go
import os
from datetime import datetime
from collections import deque
import psutil


def setSuggestion(agent_suggestions):
    try:
        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        client_socket.connect(("localhost", 8765))
        command = "setSuggestion"
        value = json.dumps(agent_suggestions)
        request = f"{command} {value}"
        client_socket.send(request.encode("utf-8"))
        client_socket.close()
    except socket.error as e:
        print(f"Something went wrong in setting suggestion... \n{e}")
        sys.exit()

def getStep():
    try:
        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        client_socket.connect(("localhost", 8765))
        command = "getStep"
        request = f"{command}"
        client_socket.send(request.encode("utf-8"))
        step_value = client_socket.recv(1024).decode("utf-8")
        client_socket.close()
        step_bool = True if step_value == 'True' or step_value == '1' or step_value == 'true' else False
        return step_bool
    except socket.error as e:
        print(f"Something went wrong in getting step... \n{e}")
        sys.exit()

def setStep(step_value):
    try:
        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        client_socket.connect(("localhost", 8765))
        command = "setStep"
        value = json.dumps(step_value)
        request = f"{command} {value}"
        client_socket.send(request.encode("utf-8"))
        client_socket.close()
    except socket.error as e:
        print(f"Something went wrong in setting step... \n{e}")
        sys.exit()

  

class SchedulingEnv(gym.Env[np.ndarray, Union[int, np.ndarray]]):

    metadata = {
        "render_modes": ["human", "rgb_array"],
        "render_fps": 50,
    }



    def __init__(self, render_mode: Optional[str] = None):

        self.worker_ips = get_worker_nodes_internal_ips()
        self.num_of_nodes = None
        self.min_usage = np.zeros(node_count()-1, dtype=np.float32)
        self.max_usage = np.full(node_count()-1, float('inf'), dtype=np.float32)
        self.action_space = spaces.Discrete(node_count()-1)
        self.observation_space = spaces.Box(self.min_usage, self.max_usage,  dtype=np.float32) #values of resource usage in range [min_usage, max_usage]    
        self.usage_treshold = 1
        self.steps_beyond_terminated = None
        self.screen = None
        self.policy="LA" #set MA, LA or LC policy
        self.graphs()
        self.reset()



    def reset(
        self,
        *,
        seed: Optional[int] = None,
        options: Optional[dict] = None,
    ):
        super().reset(seed=seed)
        self.state = get_nodes_state(self.policy, self.worker_ips)
        self.num_of_nodes = node_count()

        return np.array(self.state, dtype=np.float32), {}
    




    def step(self, action):
        assert self.action_space.contains(
            action
        ), f"{action!r} ({type(action)}) invalid"
        assert self.state is not None, "Call reset before using step method."

        reward = 0
        
        print(f"STEP VALUE...{getStep()}")   
        while getStep() != True:
            print(f"Waiting for suggestion request...")
            time.sleep(0.5) 
        
        ####################### APPLY SUGGESTION (ACTION) ON CLUSTER #########################

        agent_suggestions = {}
        node_names= self.worker_ips
        for i, node_name in enumerate(node_names):
            if i == (action):
                agent_suggestions[node_name] = 10
            else:
                agent_suggestions[node_name] = 1
        print(f"agent_suggestions: {agent_suggestions}")
        setSuggestion(agent_suggestions)

        setStep(False) 
        print(f"STEP VALUE SHOULD BE FALSE...{getStep()}")  
        
        
           

        
        node_to_select = -1  # Start from no node to select
        node_to_not_select = -1

        ########################   MOST ALLOCATED POLICY  ############################
        ##############################################################################

        if self.policy == "MA":
            #evaluate action 
            max_resource_usage = float(0)     

            for i, usage in enumerate(self.state):  #find node that has highest resource utilization
                resource_usage = usage
                if resource_usage > max_resource_usage:
                    max_resource_usage = resource_usage
                    node_to_select = i

            if node_to_select != -1:        
                print(f"action: {action}   node_to_select: {node_to_select +1}")
                terminated = action.__eq__(node_to_select + 1)  
            else:
                print("No node suggested. Suggest don't schedule.")

            # REWARD   
            unused_nodes = sum(1 for value in self.state if value < 10)
            reward = int((unused_nodes/(self.num_of_nodes -1))*10 if terminated else 0)  
            print(f"TERMINATED: {terminated}")
            print(f"REWARD: {reward}")

        ########################   LEAST ALLOCATED  POLICY  ############################
        ################################################################################

        elif self.policy == "LA":
            # evaluate action 
            min_resource_usage = float('inf') 
            max_resource_usage = float('-inf') 
            almost_terminated = False   

            for i, usage in enumerate(self.state):  #find node that has lower resource utilization
                resource_usage = usage
                if resource_usage < min_resource_usage:
                    min_resource_usage = resource_usage
                    node_to_select = i
                    print(f"Node with min usage: {node_to_select}")

            for i, usage in enumerate(self.state): #find node that has gratest reource utilization
                resource_usage = usage
                if resource_usage > max_resource_usage:
                    max_resource_usage = resource_usage
                    node_to_not_select = i
                    print(f"Node with max usage: {node_to_not_select}")

            terminated = action.__eq__(node_to_not_select)
            almost_terminated = action.__ne__(node_to_select) and action.__ne__(node_to_not_select)
            
            # REWARD
            reward = 10 if action.__eq__(node_to_select) else (0 if almost_terminated else -1)
            print(f"action: {action}   node_to_select: {node_to_select}") 
            
            """ elif self.policy == "LA":
            # evaluate action 
            min_resource_usage = float('inf') 
            max_resource_usage = float('-inf') 
            almost_terminated = False   

            for i, usage in enumerate(self.state):  #find node that has lower resource utilization
                resource_usage = usage
                if resource_usage < min_resource_usage:
                    min_resource_usage = resource_usage
                    node_to_select = i
                    print(f"Node with min usage: {node_to_select}")

            for i, usage in enumerate(self.state): #find node that has gratest reource utilization
                resource_usage = usage
                if resource_usage > max_resource_usage:
                    node_to_not_select = i
                    print(f"Node with max usage: {node_to_not_select}")

            terminated = action.__eq__(node_to_not_select)
            almost_terminated = action.__ne__(node_to_select) and action.__ne__(node_to_not_select)
            
            # REWARD
            reward = 10 if action.__eq__(node_to_select) else (0 if almost_terminated else -1)
            print(f"action: {action}   node_to_select: {node_to_select}") """ 

        ########################   LEAST CONNECTIONS  POLICY  ############################
        ##################################################################################
            
        elif self.policy == "LC":
            # evaluate action 
            min_connections = float('inf') 
            max_connections = float('-inf')    

            for i, connections in enumerate(self.state):  #find node that has fewest active connections
                active_connections = connections 
                if active_connections <  min_connections:
                    min_connections = active_connections
                    node_to_select = i
                if active_connections > max_connections:
                    max_connections = active_connections

            if node_to_select != -1:
                print(f"action: {action}   node_to_select: {node_to_select +1}")
                terminated = action.__eq__(node_to_select + 1)
                
            else:
                print("No node suggested. Suggest don't schedule.")

            # REWARD
            reward = 1 if terminated else 0 
            print(f"TERMINATED: {terminated}")
            print(f"REWARD: {reward}")

        self.state = get_nodes_state(self.policy, self.worker_ips) # update state after action to set reward
        #update nodes file
        file_path = '/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/nodes.txt'
        with open(file_path, 'a') as f:
            current_time = datetime.now().strftime("%H:%M:%S.%f")[:-3] 
            node1, node2, node3 = self.state[:3]
            f.write(str(current_time)  + ' ' + str(node1) + ' ' + str(node2) + ' ' + str(node3) +'\n')
        """ #if file is too big
        with open(file_path, 'r') as f:
            lines = f.readlines()
            if len(lines) > 500:
                lines = lines[10:]

        with open(file_path, 'w') as f:
            f.writelines(lines) """


        """ 
        #update reward file
        file_path = '/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/reward.txt'
        with open(file_path, 'a') as f:
            current_time = datetime.now().strftime("%H:%M:%S.%f")[:-3] 
            f.write(str(current_time) + ' ' + str(reward) +'\n')
        #if file is too big
        with open(file_path, 'r') as f:
            lines = f.readlines()
            if len(lines) > 500:
                lines = lines[10:]

        with open(file_path, 'w') as f:
            f.writelines(lines) """

        #update suggestion file
        
        file_path_2 = '/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/suggestion.txt'
        with open(file_path_2, 'a') as f:
            current_time = datetime.now().strftime("%H:%M:%S.%f")[:-3] 
            f.write(str(current_time) + ' ' + str(action) + ' ' + str(node_to_select)+'\n')
        """         #if file is too big
        with open(file_path, 'r') as f:
            lines = f.readlines()
            if len(lines) > 500:
                lines = lines[10:]

        with open(file_path, 'w') as f:
            f.writelines(lines) """
            
        setStep(False) 
           
        return np.array(self.state, dtype=np.float32), reward, terminated, False, {}
    
    def graphs(self):
        app = dash.Dash(__name__)
        app.layout = html.Div([
            dcc.Graph(id='dynamic-graph'),
            dcc.Graph(id='dynamic-graph-2'),
            dcc.Interval(
                id='interval-component',
                interval=1000, 
                n_intervals=0
            )
        ])

        #Nodes graph
        initial_figure = go.Figure()
        initial_figure.add_trace(go.Scatter(x=[], y=[], mode='lines', name='node0'))
        initial_figure.add_trace(go.Scatter(x=[], y=[], mode='lines', name='node1'))
        initial_figure.add_trace(go.Scatter(x=[], y=[], mode='lines', name='node2'))       
        initial_figure.update_layout(title='Nodes Metrics Comparison Chart', xaxis_title='Time', yaxis_title='Avg Metrics Value')

        #Node to select graph
        initial_figure_2 = go.Figure()
        initial_figure_2.add_trace(go.Scatter(x=[], y=[], mode='lines', name='Suggested Node'))
        initial_figure_2.add_trace(go.Scatter(x=[], y=[], mode='lines', name='Node to select'))
        initial_figure_2.update_layout(title='Suggested Node Comparison Chart', xaxis_title='Time', yaxis_title='Node')



        def run_dash_server():
            app.run_server(debug=True, port=8050)

        @app.callback(
            Output('dynamic-graph', 'figure'),
            [Input('interval-component', 'n_intervals')]
        )
        def update_graph(n_intervals):
            buffer_size = 1000
            x_data = deque(maxlen=buffer_size)
            y1_data = deque(maxlen=buffer_size)
            y2_data = deque(maxlen=buffer_size)
            y3_data = deque(maxlen=buffer_size)
            
            if not os.path.exists('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/nodes.txt'):
                with open('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/nodes.txt', 'w') as f:
                    pass
            with open('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/nodes.txt', 'r') as f:
                for line in f:
                    time, node1, node2, node3 = line.strip().split()
                    x_data.append(time)
                    y1_data.append(node1)
                    y2_data.append(node2)
                    y3_data.append(node3)

            x_data = list(x_data) 
            y1_data = list(y1_data)  
            y2_data = list(y2_data)  
            y3_data = list(y3_data)  

            trace1 = go.Scatter(x=x_data, y=y1_data, mode='lines', marker={'size': 5}, name='Node0')
            trace2 = go.Scatter(x=x_data, y=y2_data, mode='lines', marker={'size': 5}, name='Node1')
            trace3 = go.Scatter(x=x_data, y=y3_data, mode='lines', marker={'size': 5}, name='Node2')
            
            updated_figure = {'data': [trace1, trace2, trace3], 'layout': {
                'title': 'Nodes Metrics Comparison Chart',
                'xaxis': {'title': 'Time', 'autorange': 'true'},
                'yaxis': {'title': 'Avg Metrics Value'},
                'scrollZoom': 'x'
            }}

            return updated_figure
            '''
        def update_graph(n_intervals):
            buffer_size = 400
            x_data = deque(maxlen=buffer_size)
            y_data = deque(maxlen=buffer_size)
            
            if not os.path.exists('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/reward.txt'):
                with open('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/reward.txt', 'w') as f:
                    pass
            with open('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/reward.txt', 'r') as f:
                for line in f:
                    time, reward = line.strip().split()
                    x_data.append(time)
                    y_data.append(int(reward))

            x_data = list(x_data) 
            y_data = list(y_data)  

            trace = go.Scatter(x=x_data, y=y_data, mode='lines', marker={'size': 5}) 
            updated_figure = {'data': [trace], 'layout': {
                'title': 'Reward function',
                'xaxis': {'title': 'Time', 'autorange': 'true'},
                'yaxis': {'title': 'Reward'},
                'scrollZoom': 'x'  
            }}

            return updated_figure
            '''
        
        @app.callback(
            Output('dynamic-graph-2', 'figure'),
            [Input('interval-component', 'n_intervals')]
        )
        def update_graph_2(n_intervals):
            buffer_size = 400
            x_data = deque(maxlen=buffer_size)
            y1_data = deque(maxlen=buffer_size)
            y2_data = deque(maxlen=buffer_size)

            if not os.path.exists('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/suggestion.txt'):
                # Se non esiste, crea il file
                with open('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/suggestion.txt', 'w') as f:
                    pass
            with open('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/suggestion.txt', 'r') as f:
                for line in f:
                    time, suggestion, to_select = line.strip().split()
                    x_data.append(time)
                    y1_data.append(int(suggestion))
                    y2_data.append(int(to_select))

            x_data = list(x_data) 
            y1_data = list(y1_data)  
            y2_data = list(y2_data)  
            
            trace1 = go.Scatter(x=x_data, y=y1_data, mode='lines', marker={'size': 5}, name='Suggested Node')
            trace2 = go.Scatter(x=x_data, y=y2_data, mode='lines', marker={'size': 5}, name='Node to select')
            
            updated_figure = {'data': [trace1, trace2], 'layout': {
                'title': 'Suggested Node Comparison Chart',
                'xaxis': {'title': 'Time', 'autorange': 'true'},
                'yaxis': {'title': 'Node'},
                'scrollZoom': 'x'
            }}

            return updated_figure

        dash_process = multiprocessing.Process(target=run_dash_server)
        dash_process.start()
    

    def close(self):
        file_path = '/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/reward.txt'
        os.remove(file_path)
        file_path2 = '/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/suggestion.txt'
        os.remove(file_path2)
        file_path3 = '/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/nodes.txt'
        os.remove(file_path3)
        # Chiusura del server Dash
        for proc in psutil.process_iter():
            if proc.name() == "python" and proc.pid != os.getpid():
                for conns in proc.connections("tcp"):
                    (ip, port) = conns.laddr
                    if port == 8050:
                        proc.terminate()
                        proc.wait()
                        break
        if self.screen is not None:
            import pygame
            pygame.display.quit()
            pygame.quit()
            self.isopen = False

            
