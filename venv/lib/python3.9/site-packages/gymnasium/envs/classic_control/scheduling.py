import sys
sys.path.append('/etc/kubernetes') 
from typing import Optional, Union
import numpy as np
import gymnasium as gym
from gymnasium import spaces
from model.main import node_count, get_worker_nodes_internal_ips, get_nodes_state
import time
import socket
import json
import matplotlib.pyplot as plt 
import dash
from dash import dcc, html, Input, Output
import multiprocessing
import plotly.graph_objs as go
import os
from datetime import datetime
from collections import deque
import psutil
import requests
import plotly.express as px



def setSuggestion(agent_suggestions):
    try:
        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        client_socket.connect(("localhost", 8765))
        command = "setSuggestion"
        value = json.dumps(agent_suggestions)
        request = f"{command} {value}"
        client_socket.send(request.encode("utf-8"))
        client_socket.close()
    except socket.error as e:
        print(f"Something went wrong in setting suggestion... \n{e}")
        sys.exit()

def getStep():
    try:
        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        client_socket.connect(("localhost", 8765))
        command = "getStep"
        request = f"{command}"
        client_socket.send(request.encode("utf-8"))
        step_value = client_socket.recv(1024).decode("utf-8")
        client_socket.close()
        step_bool = True if step_value == 'True' or step_value == '1' or step_value == 'true' else False
        return step_bool
    except socket.error as e:
        print(f"Something went wrong in getting step... \n{e}")
        sys.exit()

def getLatency(node_ip):
    try:
        response = requests.get(f"http://{node_ip}:8100/")
        if response.status_code == 200:
            return response.text
        else:
            print(f"Failed to get latency for node {node_ip}. Status code: {response.status_code}")
            return None
    except requests.RequestException as e:
        print(f"Something went wrong in getting latency for node {node_ip}... \n{e}")
        return None
    
def get_latency_state(ips):
    metrics = [] 
    for i, node in enumerate(ips): 
        latency = getLatency(node)
        if latency: 
             metrics.append(float(latency))
        else:
            print(f"Something went wrong in getting latency... \n")

    return metrics

def setStep(step_value):
    try:
        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        client_socket.connect(("localhost", 8765))
        command = "setStep"
        value = json.dumps(step_value)
        request = f"{command} {value}"
        client_socket.send(request.encode("utf-8"))
        client_socket.close()
    except socket.error as e:
        print(f"Something went wrong in setting step... \n{e}")
        sys.exit()

def getResourceValues():
    try:
        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        client_socket.connect(("localhost", 8765))
        command = "getResourceValues"
        request = f"{command}"
        client_socket.send(request.encode("utf-8"))
        values = client_socket.recv(1024).decode("utf-8")
        client_socket.close()
        resource_values_dict = json.loads(values)
        return resource_values_dict
    except socket.error as e:
        print(f"Something went wrong in getting requested resource values... \n{e}")
        sys.exit()

  

class SchedulingEnv(gym.Env[np.ndarray, Union[int, np.ndarray]]):

    metadata = {
        "render_modes": ["human", "rgb_array"],
        "render_fps": 50,
    }



    def __init__(self, render_mode: Optional[str] = None):

        self.worker_ips = get_worker_nodes_internal_ips()
        self.num_of_nodes = None
        self.min_state = np.zeros((node_count()-1)*4, dtype=np.float32)
        self.max_state = np.full((node_count()-1)*4, float('inf'), dtype=np.float32)
        self.action_space = spaces.Discrete(node_count()-1)
        self.observation_space = spaces.Box(self.min_state, self.max_state,  dtype=np.float32) #values of resource usage in range [min_usage, max_usage]    
        self.usage_treshold = 1
        self.steps_beyond_terminated = None
        self.screen = None
        self.policy="P0" #set MA, LA , LC or P0 policy
        self.graphs()
        self.reset()



    def reset(
        self,
        *,
        seed: Optional[int] = None,
        options: Optional[dict] = None,
    ):
        super().reset(seed=seed)
        server_state =get_nodes_state(self.policy, self.worker_ips)
        latency_state = get_latency_state (self.worker_ips)            

        self.state = np.concatenate((server_state, latency_state), axis=0)
        self.num_of_nodes = node_count()
        self.requested_resources = getResourceValues()

        return np.array(self.state, dtype=np.float32), {}
    




    def step(self, action):
        assert self.action_space.contains(
            action
        ), f"{action!r} ({type(action)}) invalid"
        assert self.state is not None, "Call reset before using step method."

        reward = 0
          
        while getStep() != True:
            time.sleep(0.5) 
        
        ####################### APPLY SUGGESTION (ACTION) ON CLUSTER #########################

        agent_suggestions = {}
        node_names= self.worker_ips
        action_node_ip = 0
        for i, node_name in enumerate(node_names):
            if i == (action):
                agent_suggestions[node_name] = 10
                action_node_ip=node_name
            else:
                agent_suggestions[node_name] = 1
        print(f"agent_suggestions: {agent_suggestions}")
        setSuggestion(agent_suggestions)

        setStep(False) 
        print(f"STEP VALUE SHOULD BE FALSE...{getStep()}")  
        
           

        
        node_to_select = -1  # Start from no node to select
        node_to_not_select = -1

        ########################   MOST ALLOCATED POLICY  ############################
        ##############################################################################

        if self.policy == "MA":
            #evaluate action 
            max_resource_usage = float(0)     

            for i, usage in enumerate(self.state):  #find node that has highest resource utilization
                resource_usage = usage
                if resource_usage > max_resource_usage:
                    max_resource_usage = resource_usage
                    node_to_select = i

            if node_to_select != -1:        
                print(f"action: {action}   node_to_select: {node_to_select +1}")
                terminated = action.__eq__(node_to_select + 1)  
            else:
                print("No node suggested. Suggest don't schedule.")

            # REWARD   
            unused_nodes = sum(1 for value in self.state if value < 10)
            reward = int((unused_nodes/(self.num_of_nodes -1))*10 if terminated else 0)  
            print(f"TERMINATED: {terminated}")
            print(f"REWARD: {reward}")

        ########################   LEAST ALLOCATED  POLICY  ############################
        ################################################################################

        elif self.policy == "LA":
            # evaluate action 
            min_resource_usage = float('inf') 
            max_resource_usage = float('-inf') 
            almost_terminated = False   

            for i, usage in enumerate(self.state):  #find node that has lower resource utilization
                resource_usage = usage
                if resource_usage < min_resource_usage:
                    min_resource_usage = resource_usage
                    node_to_select = i
                    print(f"Node with min usage: {node_to_select}")

            for i, usage in enumerate(self.state): #find node that has gratest reource utilization
                resource_usage = usage
                if resource_usage > max_resource_usage:
                    max_resource_usage = resource_usage
                    node_to_not_select = i
                    print(f"Node with max usage: {node_to_not_select}")

            terminated = action.__eq__(node_to_not_select)
            almost_terminated = action.__ne__(node_to_select) and action.__ne__(node_to_not_select)
            
            # REWARD
            reward = 10 if action.__eq__(node_to_select) else (0 if almost_terminated else -1)
            print(f"action: {action}   node_to_select: {node_to_select}") 
            
            """ elif self.policy == "LA":
            # evaluate action 
            min_resource_usage = float('inf') 
            max_resource_usage = float('-inf') 
            almost_terminated = False   

            for i, usage in enumerate(self.state):  #find node that has lower resource utilization
                resource_usage = usage
                if resource_usage < min_resource_usage:
                    min_resource_usage = resource_usage
                    node_to_select = i
                    print(f"Node with min usage: {node_to_select}")

            for i, usage in enumerate(self.state): #find node that has gratest reource utilization
                resource_usage = usage
                if resource_usage > max_resource_usage:
                    node_to_not_select = i
                    print(f"Node with max usage: {node_to_not_select}")

            terminated = action.__eq__(node_to_not_select)
            almost_terminated = action.__ne__(node_to_select) and action.__ne__(node_to_not_select)
            
            # REWARD
            reward = 10 if action.__eq__(node_to_select) else (0 if almost_terminated else -1)
            print(f"action: {action}   node_to_select: {node_to_select}") """ 

        ########################   LEAST CONNECTIONS  POLICY  ############################
        ##################################################################################
            
        elif self.policy == "LC":
            # evaluate action 
            min_connections = float('inf') 
            max_connections = float('-inf')    

            for i, connections in enumerate(self.state):  #find node that has fewest active connections
                active_connections = connections 
                if active_connections <  min_connections:
                    min_connections = active_connections
                    node_to_select = i
                if active_connections > max_connections:
                    max_connections = active_connections

            if node_to_select != -1:
                print(f"action: {action}   node_to_select: {node_to_select +1}")
                terminated = action.__eq__(node_to_select + 1)
                
            else:
                print("No node suggested. Suggest don't schedule.")

            # REWARD
            reward = 1 if terminated else 0 
            print(f"TERMINATED: {terminated}")
            print(f"REWARD: {reward}")

        ########################   P0  POLICY  ############################
        ##################################################################################
            
        elif self.policy == "P0": 
            #cpuRequest, memoryRequest, latencySoftConstraint, latencyHardConstraint = [value for _, value in self.requested_resources[:4]]
            latencySoftConstraint = self.requested_resources["latencySoftConstraint"]
            latencyHardConstraint = self.requested_resources["latencyHardConstraint"]
            print(f"Soft constraint: {latencySoftConstraint}, hard constraint:{latencyHardConstraint} ")

            max_latency = float(0)    
            for i, latency in enumerate(self.state[-3:]):  #find node with highest latency
                node_latency = latency
                if node_latency > max_latency:
                    max_latency = node_latency
                    node_to_not_select = i 

            # REWARD  
            scheduled_pods = self.state[:self.num_of_nodes-1] #slice of state that contains number of pod on each node
            print(f"PODS STATE: {scheduled_pods}")
            on_nodes = sum(1 for value in scheduled_pods if value > 5)
            r1 = (self.num_of_nodes - on_nodes)/ self.num_of_nodes #reward member to minimize the number of used nodes
            tot_pods = np.sum(scheduled_pods)
            r2 = tot_pods/on_nodes # reward member to host pods on min number of nodes [0, 1]
            r2_min = 0  # no pods scheduled
            r2_max = 50  # all pods scheduled on the single on_node
        
            if on_nodes > 0:
                r2 = (r2 - r2_min) / (r2_max - r2_min)
            else:
                r2 = 0  

            latency_node_user = float(getLatency(action_node_ip))

            r3 = 0
            if latencyHardConstraint!= -1 and latencySoftConstraint!= -1:
                if latency_node_user > latencyHardConstraint:
                    r3 = 0
                elif (latencySoftConstraint< latency_node_user) and (latency_node_user <= latencyHardConstraint):
                    r3 = 5
                elif latency_node_user <= latencySoftConstraint:
                    r3 = 10
            else:
                r3 = 0

            reward = r1 + r2 + r3
            print(f"REWARD: r1 = {r1}, r2 = {r2}, r3 = {r3}")
            terminated = action.__eq__(node_to_not_select)  

        server_state =get_nodes_state(self.policy, self.worker_ips)
        latency_state = get_latency_state(self.worker_ips)            

        self.state = np.concatenate((server_state, latency_state), axis=0) # update state after action to set reward

        #update #pods on nodes file
        file_path = '/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/pods.txt'
        with open(file_path, 'a') as f:
            current_time = datetime.now().strftime("%H:%M:%S.%f")[:-3] 
            node1, node2, node3 = self.state[:3]
            f.write(str(current_time)  + ' ' + str(node1) + ' ' + str(node2) + ' ' + str(node3) +'\n')
        
        #update latency file 
        file_path_2 = '/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/latency.txt'
        with open(file_path_2, 'a') as f:
            current_time = datetime.now().strftime("%H:%M:%S.%f")[:-3] 
            node1, node2, node3 = latency_state[:3]
            f.write(str(current_time)  + ' ' + str(node1) + ' ' + str(node2) + ' ' + str(node3) +'\n')
            
        setStep(False) 
           
        return np.array(self.state, dtype=np.float32), reward, terminated, False, {}
    
    def graphs(self):
        app = dash.Dash(__name__)
        app.layout = html.Div(
            style={'backgroundColor': '#222222', 'color': 'white', 'height': '100vh','display': 'flex', 'flexDirection': 'column', 'alignItems': 'center', 'margin': '0'},
            children=[
                html.H1(children='Monitoring Dashboard', style={'textAlign': 'center'}), 
                html.Div([  
                    dcc.Graph(
                        id='node-pods'),
                    dcc.Graph(id='node-user-latency'),
                    dcc.Interval(
                        id='interval-component',
                        interval=1000, 
                        n_intervals=0
                    )
                ], style={'display': 'flex', 'alignItems': 'center', 'margin': '20px 0'})

            ]
        )

        """ html.Div([
                    dcc.Graph(id='cpu-bar-chart'),
                    dcc.Graph(id='memory-bar-chart'),
                    dcc.Interval(
                        id='interval-component-2',
                        interval=1000, 
                        n_intervals=0
                    )
                ], style={'display': 'flex'}) """

        #Nodes pods graph
        initial_figure = go.Figure()
        initial_figure.add_trace(go.Scatter(x=[], y=[], mode='lines', name='node0'))
        initial_figure.add_trace(go.Scatter(x=[], y=[], mode='lines', name='node1'))
        initial_figure.add_trace(go.Scatter(x=[], y=[], mode='lines', name='node2'))       
        initial_figure.update_layout(title='Number of scheduled pods Chart', xaxis_title='Time', yaxis_title='#Pods')

        #Nodes latency graph
        initial_figure_2 = go.Figure()
        initial_figure_2.add_trace(go.Bar(x=[], y=[],  name='Latency'))
        initial_figure_2.update_layout(title='Node-user latency Chart', xaxis_title='Time', yaxis_title='Latency')



        def run_dash_server():
            app.run_server(debug=True, port=8050)

        @app.callback(
            Output('node-pods', 'figure'),
            [Input('interval-component', 'n_intervals')]
        )
        def update_graph(n_intervals):
            buffer_size = 1000
            x_data = deque(maxlen=buffer_size)
            y1_data = deque(maxlen=buffer_size)
            y2_data = deque(maxlen=buffer_size)
            y3_data = deque(maxlen=buffer_size)
            
            if not os.path.exists('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/pods.txt'):
                with open('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/pods.txt', 'w') as f:
                    pass
            with open('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/pods.txt', 'r') as f:
                for line in f:
                    time, node1, node2, node3 = line.strip().split()
                    x_data.append(time)
                    y1_data.append(node1)
                    y2_data.append(node2)
                    y3_data.append(node3)

            x_data = list(x_data) 
            y1_data = list(y1_data)  
            y2_data = list(y2_data)  
            y3_data = list(y3_data)  

            trace1 = go.Scatter(x=x_data, y=y1_data, mode='lines', marker={'size': 5}, name='Node0')
            trace2 = go.Scatter(x=x_data, y=y2_data, mode='lines', marker={'size': 5}, name='Node1')
            trace3 = go.Scatter(x=x_data, y=y3_data, mode='lines', marker={'size': 5}, name='Node2')
            
            updated_figure = {'data': [trace1, trace2, trace3], 'layout': {
                'title': 'Number of scheduled pods Chart',
                'xaxis': {'title': 'Time', 'autorange': 'true', 'tickmode': 'array', 'tickvals': [], 'ticktext': []},
                'yaxis': {'title': '#Pods'},
                'scrollZoom': 'x'
            }}

            return updated_figure
        
        @app.callback(
            Output('node-user-latency', 'figure'),
            [Input('interval-component', 'n_intervals')]
        )
        def update_graph_2(n_intervals):
            colors = px.colors.sequential.Viridis[:3]

            if not os.path.exists('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/latency.txt'):
                # Se non esiste, crea il file
                with open('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/latency.txt', 'w') as f:
                    pass

            node1, node2, node3 = 0, 0, 0
            with open('/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/latency.txt', 'r') as f:
                for line in f:
                    time, node1, node2, node3 = line.strip().split()


            x_data = ['Node0', 'Node1', 'Node2']
            y_data = [float(node1), float(node2), float(node3)]
            
            trace1 = go.Bar(x=x_data, y=y_data,  name='Latency', marker=dict(color=colors))
            
            updated_figure = {'data': [trace1], 'layout': {
                'title': 'Node-user latency Chart',
                'xaxis': {'title': ' ', 'autorange': 'true', 'tickmode': 'array', 'tickvals':[0, 1, 2], 'ticktext': x_data},
                'yaxis': {'title': 'Latency'},
                'scrollZoom': 'x'
            }}

            return updated_figure

        dash_process = multiprocessing.Process(target=run_dash_server)
        dash_process.start()
    

    def close(self):
        file_path = '/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/reward.txt'
        os.remove(file_path)
        file_path2 = '/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/latency.txt'
        os.remove(file_path2)
        file_path3 = '/etc/kubernetes/venv/lib/python3.9/site-packages/gymnasium/envs/classic_control/pods.txt'
        os.remove(file_path3)
        # Chiusura del server Dash
        for proc in psutil.process_iter():
            if proc.name() == "python" and proc.pid != os.getpid():
                for conns in proc.connections("tcp"):
                    (ip, port) = conns.laddr
                    if port == 8050:
                        proc.terminate()
                        proc.wait()
                        break
        if self.screen is not None:
            import pygame
            pygame.display.quit()
            pygame.quit()
            self.isopen = False

            
