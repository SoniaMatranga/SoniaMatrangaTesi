import sys
sys.path.append('/etc/kubernetes') 
from typing import Optional, Union
import numpy as np
import gymnasium as gym
from gymnasium import spaces
from model.main import node_count, get_worker_nodes_internal_ips, get_nodes_state
import time
import multiprocessing
import socket
import json

def setSuggestion(agent_suggestions):
    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    client_socket.connect(("localhost", 8765))
    command = "setSuggestion"
    value = json.dumps(agent_suggestions)
    request = f"{command} {value}"
    client_socket.send(request.encode("utf-8"))
    client_socket.close()

def getStep():
    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    client_socket.connect(("localhost", 8765))
    command = "getStep"
    request = f"{command}"
    client_socket.send(request.encode("utf-8"))
    step_value = client_socket.recv(1024).decode("utf-8")
    client_socket.close()
    return step_value.strip()

def setStep(step_value):
    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    client_socket.connect(("localhost", 8765))
    command = "setStep"
    value = json.dumps(step_value)
    request = f"{command} {value}"
    client_socket.send(request.encode("utf-8"))
    client_socket.close()
  

class SchedulingEnv(gym.Env[np.ndarray, Union[int, np.ndarray]]):

    metadata = {
        "render_modes": ["human", "rgb_array"],
        "render_fps": 50,
    }

    reward_value = multiprocessing.Value('i', 0)

    @classmethod
    def setReward(cls, value):
        with cls.reward_value.get_lock():
            cls.reward_value.value = value

    @classmethod
    def getReward(cls):
        with cls.reward_value.get_lock():
            return cls.reward_value.value



    def __init__(self, render_mode: Optional[str] = None):

        self.setReward(0)
        self.worker_ips = get_worker_nodes_internal_ips()
        self.num_of_nodes = None
        self.min_usage = np.zeros(node_count()-1, dtype=np.float32)
        self.max_usage = np.full(node_count()-1, float('inf'), dtype=np.float32)
        self.num_of_actions = None
        self.action_space = spaces.Discrete(node_count()+ 1)
        self.observation_space = spaces.Box(self.min_usage, self.max_usage,  dtype=np.float32) #values of resource usage in range [min_usage, max_usage]    
        self.usage_treshold = 1
        self.steps_beyond_terminated = None
        self.screen = None
        self.policy="LA"
        self.reset()





    def reset(
        self,
        *,
        seed: Optional[int] = None,
        options: Optional[dict] = None,
    ):
        super().reset(seed=seed)
        self.state = get_nodes_state(self.policy, self.worker_ips)
        self.num_of_nodes = node_count()
        self.num_of_actions = node_count() + 1
        return np.array(self.state, dtype=np.float32), {}
    




    def step(self, action):
        assert self.action_space.contains(
            action
        ), f"{action!r} ({type(action)}) invalid"
        assert self.state is not None, "Call reset before using step method."

        
        while getStep()!= "true":
            print(f"Waiting for suggestion request...")
            time.sleep(1) 
           
        print(f"ACTION: {action}")

        # state update 
        self.state = get_nodes_state(self.policy, self.worker_ips)

        ########################   MA POLICY  ############################
        ##################################################################

        if self.policy == "MA":
            #evaluate action 
            node_to_select = -1  # Start from no node to select
            max_resource_usage = float(0)     

            for i, usage in enumerate(self.state):  #find node that has highest resource utilization
                resource_usage = usage
                if resource_usage > max_resource_usage:
                    max_resource_usage = resource_usage
                    node_to_select = i

            if node_to_select != -1:        
                print(f"action: {action}   node_to_select: {node_to_select +1}")
                terminated = action.__eq__(node_to_select + 1)  
            else:
                print("No node suggested. Suggest don't schedule.")

            # REWARD   
            unused_nodes = sum(1 for value in self.state if value < 6)
            reward = int((unused_nodes/(self.num_of_nodes -1))*10 if terminated else 0)  
            self.setReward(reward)
            print(f"TERMINATED: {terminated}")
            print(f"REWARD: {reward}")

        ########################   LA  POLICY  ############################
        ##################################################################
            
        elif self.policy == "LA":
            # evaluate action 
            node_to_select = -1  # Start from no node to select
            min_memory_usage = float('inf')     

            for i, node in enumerate(self.state):  
                network_usage = node
                if network_usage < min_memory_usage:
                    min_memory_usage = network_usage
                    node_to_select = i

            if node_to_select != -1:
                print(f"action: {action}   node_to_select: {node_to_select +1}")
                terminated = action.__eq__(node_to_select + 1)
                
            else:
                print("No node suggested. Suggest don't schedule.")

            # REWARD
            reward = 1 if terminated else 0  # Binary sparse rewards
            self.setReward(reward)
            print(f"TERMINATED: {terminated}")
            print(f"REWARD: {reward}")

        ########################   LB  POLICY  ############################
        ###################################################################

        elif self.policy == "LB":
            print("TO DO: IMPLEMENT LOAD BALANCING...")

        ####################### FINAL SUGGESTION #########################

        agent_suggestions = {}
        node_names= self.worker_ips
        for i, node_name in enumerate(node_names):
            if i == (action - 1):
                agent_suggestions[node_name] = 10
            else:
                agent_suggestions[node_name] = 1
        print(f"agent_suggestions: {agent_suggestions}")
        setSuggestion(agent_suggestions)
        setStep(False)
        
        return np.array(self.state, dtype=np.float32), reward, terminated, False, {}

    

    def close(self):
        if self.screen is not None:
            import pygame
            pygame.display.quit()
            pygame.quit()
            self.isopen = False

            
